{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5672e82d-73d4-4136-8ca5-3238cd5a2493",
   "metadata": {},
   "source": [
    "<font color=\"green\">\n",
    "    \n",
    "## 1. Fighting overfitting   \n",
    "### Here the most common ways to prevent overfitting in neural networks\n",
    "- Getting more training data.\n",
    "- Reducing the capacity of the network.\n",
    "- Adding weight regularization.\n",
    "    - *network.add (layers.Dense (16, kernel_regularizer = regularizers.l2(0.001), activation='relu'))*\n",
    "    - *network.add (layers.Dense (16, kernel_regularizer = regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))*\n",
    "- Adding dropout.\n",
    "    - *network.add (layers.Dropout(0.5))*\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301855d0-d3b6-449e-a5d7-ac24384ebd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 49.6468 - mae: 5.4789 \n",
      "The mean absolute error: 5.478940486907959\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
    "import numpy as np\n",
    "test_data = (test_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "train_data = (train_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "def build_model():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Input(shape=(train_data.shape[1],)))  # Specify the input shape\n",
    "    network.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    network.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    network.add(layers.Dense(1))\n",
    "    network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return network\n",
    "network=build_model()\n",
    "network.fit(train_data, train_labels, epochs=10, batch_size=10, verbose=0)\n",
    "test_loss, test_mae = network.evaluate(test_data, test_labels)\n",
    "print(f\"The mean absolute error: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e2f568-06f2-48fe-86ca-2586216e3f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 32.6508 - mae: 4.5953 \n",
      "The mean absolute error: 4.595333576202393\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
    "import numpy as np\n",
    "test_data = (test_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "train_data = (train_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "def build_model():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Input(shape=(train_data.shape[1],)))  # Specify the input shape\n",
    "    network.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
    "    network.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
    "    network.add(layers.Dense(1))\n",
    "    network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return network\n",
    "\n",
    "network=build_model()\n",
    "network.fit(train_data, train_labels, epochs=10, batch_size=10, verbose=0)\n",
    "test_loss, test_mae = network.evaluate(test_data, test_labels)\n",
    "print(f\"The mean absolute error: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937f4f1-59fc-49dc-aa06-75d1ae8c6a0c",
   "metadata": {},
   "source": [
    "<font color=\"green\">\n",
    "Dropout is one of the most effective and most commonly used regularization techniques\n",
    "for neural networks, developed by Hinton and his students at the University of Toronto.\n",
    "Dropout, applied to a layer, consists of randomly \"dropping out\" (i.e. setting to zero) a\n",
    "number of output features of the layer during training. Let’s say a given layer would\n",
    "normally have returned a vector for a given input sample [0.2, 0.5, 1.3, 0.8, 1.1]\n",
    "during training; after applying dropout, this vector will have a few zero entries distributed\n",
    "at random, e.g. . The \"dropout rate\" is the fraction of the [0, 0.5, 1.3, 0, 1.1]\n",
    "features that are being zeroed-out; it is usually set between 0.2 and 0.5. At test time, no\n",
    "units are dropped out, and instead the layer’s output values are scaled down by a factor\n",
    "equal to the dropout rate, so as to balance for the fact that more units are active than at\n",
    "training time.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6a8ade-64a8-4b19-9a44-1e8d8f87e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 130.4847 - mae: 9.5264 \n",
      "The mean absolute error: 9.526391983032227\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
    "import numpy as np\n",
    "test_data = (test_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "train_data = (train_data - np.mean(train_data, axis=0))/np.std(train_data, axis=0)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Input(shape=(train_data.shape[1],)))  # Specify the input shape\n",
    "    network.add(layers.Dense(16, activation='relu'))\n",
    "    network.add(layers.Dropout(0.5))\n",
    "    network.add(layers.Dense(16, activation='relu'))\n",
    "    network.add(layers.Dropout(0.5))\n",
    "    network.add(layers.Dense(1))\n",
    "    network.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return network\n",
    "\n",
    "network=build_model()\n",
    "network.fit(train_data, train_labels, epochs=10, batch_size=10, verbose=0)\n",
    "test_loss, test_mae = network.evaluate(test_data, test_labels)\n",
    "print(f\"The mean absolute error: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98590980-a620-46e0-ac48-df8e7fec5a04",
   "metadata": {},
   "source": [
    "<font color=\"green\">\n",
    "    \n",
    "## 2. Here is a table to help you pick a last-layer activation and a loss function for a few common problem types \n",
    "| Problem type      |Last-layer activation| Loss function |\n",
    "| :---------------- | :------: | ----: |\n",
    "|Binary classification                   |   sigmoid  | binary_crossentropy |\n",
    "|Multi-class, single-label classification|   softmax  | categorical_crossentropy |\n",
    "|Multi-class, multi-label classification |  softmax   | binary_crossentropy |\n",
    "|Regression to arbitrary values          |  None      | mse |\n",
    "|Regression to values between 0 and 1    |  sigmoid   | mse or binary_crossentropy |\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ae2f0-8330-44dc-b3d9-a3e0fbd797d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a40d1d-18d5-426f-a697-d1045c8bcd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
